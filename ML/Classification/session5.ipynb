{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844caf71",
   "metadata": {},
   "source": [
    "# Class Imbalance Strategies\n",
    "- Class imbalance occurs when one class in a classification problem significantly outweighs the other class. Itâ€™s common in many machine learning problems. Examples include fraud detection, anomaly detection, and medical diagnosis.\n",
    "\n",
    "These modify the training data to balance the class distribution.\n",
    "\n",
    "### 1. Oversampling\n",
    "- **Random Oversampling**: Duplicate examples from the minority class.\n",
    "- **SMOTE (Synthetic Minority Oversampling Technique)**: Create synthetic samples by interpolating between existing minority class samples.\n",
    "- **ADASYN (Adaptive Synthetic Sampling)**: Similar to SMOTE but focuses more on harder-to-learn examples.\n",
    "\n",
    "### 2. Undersampling\n",
    "- **Random Undersampling**: Remove samples from the majority class at random.\n",
    "- **Tomek Links**: Remove overlapping examples to clean the decision boundary.\n",
    "- **Cluster Centroids**: Replace the majority class with cluster centroids.\n",
    "\n",
    "### 3. Hybrid Methods\n",
    "- Combine over- and under-sampling to strike a balance  \n",
    "  (e.g., **SMOTE + Tomek Links** or **SMOTE**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08172624",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d183323c",
   "metadata": {},
   "source": [
    "# Oversampling\n",
    "- Oversampling is a technique used to handle class imbalance by increasing the number of samples in the minority class. This is done to match the size of the majority class, helping the model learn from both classes more equally.\n",
    "\n",
    "- Unlike undersampling, oversampling does not remove any data, so there is no loss of information. However, it can increase the risk of overfitting, especially if the same minority samples are simply duplicated.\n",
    "\n",
    "- For example, if you have 10,000 samples:\n",
    "\n",
    "- 9,000 belong to the majority class (True)\n",
    "\n",
    "- 1,000 belong to the minority class (False)\n",
    "\n",
    "- You can apply oversampling by replicating or generating new samples in the minority class to increase it to 9,000, matching the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9bb68",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "- Undersampling is a technique used to handle class imbalance by reducing the number of samples in the majority class. This helps balance the dataset and can prevent the model from being biased toward the majority class.\n",
    "\n",
    "- However, since undersampling discards data from the majority class, it may lead to the loss of important information, which can negatively impact model performance.\n",
    "\n",
    "- For example, suppose you have 10,000 samples, where:\n",
    "\n",
    "- 9,000 belong to the majority class (True)\n",
    "\n",
    "- 1,000 belong to the minority class (False)\n",
    "\n",
    "- If you keep all 1,000 samples from the minority class and randomly select 1,000 from the majority class (ignoring the remaining 8,000), this is called random undersampling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e80a0",
   "metadata": {},
   "source": [
    "- In undersampling, you reduce the number of majority class samples to match the minority class size. Then you train the model using this balanced dataset (both classes are present, but the majority class has fewer samples than before).\n",
    "\n",
    "- In oversampling, you increase the number of minority class samplesâ€”usually by duplicating them or generating synthetic examplesâ€”to match the majority class. This also results in a balanced dataset, but without removing data from the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36c7b2",
   "metadata": {},
   "source": [
    "# SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "### ðŸ“Œ What is SMOTE?\n",
    "- SMOTE is an advanced oversampling technique used to deal with class imbalance in datasets.\n",
    "Instead of simply duplicating existing minority class samples, SMOTE generates new, synthetic samples by interpolating between existing ones.\n",
    "### ðŸ’¡ How Does It Work?\n",
    "- For each sample in the minority class, SMOTE:\n",
    "- Finds its k nearest neighbors (usually k=5) among other minority class samples.\n",
    "- It then randomly selects one of those neighbors.\n",
    "- A new synthetic sample is created by picking a point along the line between the original sample and the neighbor.\n",
    "- This makes the new data more diverse and less prone to overfitting than simple duplication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414742c",
   "metadata": {},
   "source": [
    "# SMOTE + Tomek Links\n",
    "- ðŸ”„ What is it?\n",
    "- SMOTE + Tomek Links is a two-step process that:\n",
    "- Uses SMOTE to generate synthetic minority class samples (oversampling)\n",
    "- Uses Tomek Links to clean the dataset by removing overlapping samples (undersampling)\n",
    "- After Applying smote you create synthetic data for minority class we need to check the nearest neighbours of minority nodes if the node is generated by synthetic data and near by data point is majority node the tomek links helps to delete the new synthetic node this helps in balancing the dataset\n",
    "\n",
    "\n",
    "### This helps in:\n",
    "\n",
    "- Balancing the dataset\n",
    "\n",
    "- Removing noisy or borderline samples that might confuse the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9a6a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Class Imbalance Using imblearn: Churn Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f059069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5d334aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call  Failure</th>\n",
       "      <th>Complains</th>\n",
       "      <th>Subscription  Length</th>\n",
       "      <th>Charge  Amount</th>\n",
       "      <th>Seconds of Use</th>\n",
       "      <th>Frequency of use</th>\n",
       "      <th>Frequency of SMS</th>\n",
       "      <th>Distinct Called Numbers</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Tariff Plan</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Value</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4370</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>197.640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>46.035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2453</td>\n",
       "      <td>60</td>\n",
       "      <td>359</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1536.520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4198</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>240.020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2393</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>145.805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n",
       "0              8          0                    38               0   \n",
       "1              0          0                    39               0   \n",
       "2             10          0                    37               0   \n",
       "3             10          0                    38               0   \n",
       "4              3          0                    38               0   \n",
       "\n",
       "   Seconds of Use  Frequency of use  Frequency of SMS  \\\n",
       "0            4370                71                 5   \n",
       "1             318                 5                 7   \n",
       "2            2453                60               359   \n",
       "3            4198                66                 1   \n",
       "4            2393                58                 2   \n",
       "\n",
       "   Distinct Called Numbers  Age Group  Tariff Plan  Status  Age  \\\n",
       "0                       17          3            1       1   30   \n",
       "1                        4          2            1       2   25   \n",
       "2                       24          3            1       1   30   \n",
       "3                       35          1            1       1   15   \n",
       "4                       33          1            1       1   15   \n",
       "\n",
       "   Customer Value  Churn  \n",
       "0         197.640      0  \n",
       "1          46.035      0  \n",
       "2        1536.520      0  \n",
       "3         240.020      0  \n",
       "4         145.805      0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\utils\\\\DataSets\\\\churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df2c4dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    2655\n",
       "1     495\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "733a1b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call  Failure              0\n",
       "Complains                  0\n",
       "Subscription  Length       0\n",
       "Charge  Amount             0\n",
       "Seconds of Use             0\n",
       "Frequency of use           0\n",
       "Frequency of SMS           0\n",
       "Distinct Called Numbers    0\n",
       "Age Group                  0\n",
       "Tariff Plan                0\n",
       "Status                     0\n",
       "Age                        0\n",
       "Customer Value             0\n",
       "Churn                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fab2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn', axis=1)  \n",
    "y = df['Churn']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59847870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       531\n",
      "           1       0.82      0.42      0.56        99\n",
      "\n",
      "    accuracy                           0.90       630\n",
      "   macro avg       0.86      0.70      0.75       630\n",
      "weighted avg       0.89      0.90      0.88       630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adari Shanmukh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=2000)  # Increase max_iter if convergence issues occur\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39cd5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The under sampling and over Sampling will be done only on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fdc5b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    396\n",
       "1    396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train_rus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c0aa210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2430    0\n",
       "1471    0\n",
       "1423    0\n",
       "2662    0\n",
       "1011    0\n",
       "       ..\n",
       "3099    1\n",
       "2378    1\n",
       "2268    1\n",
       "1831    1\n",
       "1631    1\n",
       "Name: Churn, Length: 792, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc675195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88       531\n",
      "           1       0.45      0.84      0.58        99\n",
      "\n",
      "    accuracy                           0.81       630\n",
      "   macro avg       0.71      0.82      0.73       630\n",
      "weighted avg       0.88      0.81      0.83       630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adari Shanmukh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=2000)  # Increase max_iter if convergence issues occur\n",
    "model.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rus = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred_rus)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be761df",
   "metadata": {},
   "source": [
    "| Metric     | Definition                                                                                                                               |\n",
    "|------------|------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Precision  | Out of all the items the model predicted as positive, what proportion were actually positive? (True Positives / (True Positives + False Positives)) |\n",
    "| Recall     | Out of all the actual positive items, what proportion did the model correctly identify? (True Positives / (True Positives + False Negatives))    |\n",
    "| F1-score   | The harmonic mean of precision and recall, providing a balanced measure of the model's accuracy. (2 * (Precision * Recall) / (Precision + Recall)) |\n",
    "| Support    | The number of actual occurrences of the class in the dataset.                                                                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57d60d",
   "metadata": {},
   "source": [
    "In summary:\n",
    "\n",
    "* **Precision** focuses on the accuracy of the positive predictions.\n",
    "* **Recall** focuses on the model's ability to find all the actual positive instances.\n",
    "* **F1-score** provides a balanced measure of both.\n",
    "* **Support** indicates the number of actual instances of each class.\n",
    "\n",
    "These metrics are crucial for evaluating the performance of classification models. Depending on the specific problem, you might prioritize one metric over the others. For instance, in a spam detection system, high precision might be more important to avoid incorrectly classifying legitimate emails as spam (false positives). In a medical diagnosis system, high recall might be more critical to ensure that all actual cases of a disease are identified (minimizing false negatives).\n",
    "\n",
    "âœ… Precision increasing:\n",
    "The model is making fewer false positive errors â€” it's getting better at not misclassifying negative examples as positive.\n",
    "\n",
    "âœ… Recall increasing:\n",
    "The model is making fewer false negative errors â€” it's getting better at finding all the actual positive cases.\n",
    "\n",
    "âœ… F1-score increasing:\n",
    "Since F1 is the harmonic mean of precision and recall, its improvement confirms that both precision and recall are improving together, and not at the expense of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bbbf13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    2124\n",
       "1    2124\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52e09177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88       531\n",
      "           1       0.45      0.85      0.59        99\n",
      "\n",
      "    accuracy                           0.81       630\n",
      "   macro avg       0.71      0.83      0.73       630\n",
      "weighted avg       0.88      0.81      0.83       630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adari Shanmukh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_smote = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred_smote)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d25325c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    2091\n",
       "1    2091\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_tomek, y_tomek = smt.fit_resample(X_train, y_train)\n",
    "y_tomek.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14609691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88       531\n",
      "           1       0.45      0.86      0.59        99\n",
      "\n",
      "    accuracy                           0.81       630\n",
      "   macro avg       0.71      0.83      0.73       630\n",
      "weighted avg       0.89      0.81      0.83       630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adari Shanmukh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_tomek, y_tomek)\n",
    "\n",
    "y_pred_tomek = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred_tomek)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
